{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "338ea56c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:20:20.672358Z",
     "start_time": "2024-05-17T12:20:19.891150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97b841c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:20:21.132090Z",
     "start_time": "2024-05-17T12:20:20.676884Z"
    }
   },
   "outputs": [],
   "source": [
    "# List all daily report files for ship position...\n",
    "joined_list_pos = glob.glob(\"data/position_day*.csv\") \n",
    "\n",
    "# ...and ship data\n",
    "joined_list_ship = glob.glob(\"data/ship_data_day*.csv\") \n",
    "\n",
    "# Create unified dataframes\n",
    "df_positions = pd.concat(map(pd.read_csv, joined_list_pos), ignore_index=True)\n",
    "df_ships_data = pd.concat(map(pd.read_csv, joined_list_ship), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121b4fa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:20:21.163084Z",
     "start_time": "2024-05-17T12:20:21.134777Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define new column names\n",
    "positions_columns = ['COG', 'Latitude', 'Longitude', 'NavigationalStatus', 'PositionAccuracy',\n",
    "                    'RateOfTurn', 'SOG', 'TrueHeading', 'MMSI', 'ShipName', 'UTC_Time']\n",
    "\n",
    "ships_columns = ['CallSign', 'Destination', 'ETA_Day', 'ETA_Hour', 'ETA_Minute', 'ETA_Month', 'IMO', 'ShipName',\n",
    "                'ShipType', 'MMSI', 'Latitude', 'Longitude', 'UTC_Time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04a29abf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:20:21.300935Z",
     "start_time": "2024-05-17T12:20:21.199484Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "\n",
    "df_positions.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "df_ships_data.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "\n",
    "df_positions = df_positions.set_axis(positions_columns, axis = 1)\n",
    "df_ships_data = df_ships_data.set_axis(ships_columns, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17fa292d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:20:21.325114Z",
     "start_time": "2024-05-17T12:20:21.304077Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load MMSI Country Codes into a df...\n",
    "country_codes_df = pd.read_csv(\"data/MMSI Country Codes.csv\", delimiter=\";\", index_col=0, dtype=str)\n",
    "\n",
    "# ...And convert to dictionary\n",
    "country_codes = pd.Series(country_codes_df.Country.values, index=country_codes_df.index).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3a007d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:20:21.393278Z",
     "start_time": "2024-05-17T12:20:21.329403Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all information that can ID a ship from both AIS message types\n",
    "positions_id = df_positions[[\"MMSI\", \"ShipName\"]].drop_duplicates().astype(str)\n",
    "ships_id = df_ships_data[[\"MMSI\", \"ShipName\", \"IMO\", \"ShipType\"]].drop_duplicates().astype(str)\n",
    "\n",
    "# Merge all that information\n",
    "all_ships = positions_id.merge(ships_id, how=\"outer\", on=[\"MMSI\", \"ShipName\"])\n",
    "\n",
    "# Get each ship's country flag, which can be obtained from the first 3 digits of each MMSI\n",
    "all_ships[\"Flag\"] = all_ships[\"MMSI\"].str[:3].astype(int).map(country_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c4259a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:20:21.427805Z",
     "start_time": "2024-05-17T12:20:21.396011Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter out repeated ships\n",
    "\n",
    "all_ships = all_ships.drop(all_ships[(all_ships[\"MMSI\"] == \"374024000\") & (all_ships[\"ShipType\"] == \"89\")].index)\n",
    "all_ships = all_ships.drop(all_ships[(all_ships[\"MMSI\"] == \"314764000\") & (all_ships[\"IMO\"].isnull())].index)\n",
    "all_ships = all_ships.drop(all_ships[(all_ships[\"MMSI\"] == \"352002699\") & (all_ships[\"ShipType\"] == \"89\")].index)\n",
    "all_ships = all_ships.drop(all_ships[(all_ships[\"MMSI\"] == \"352524000\") & (all_ships[\"IMO\"].isnull())].index)\n",
    "all_ships = all_ships.drop(all_ships[(all_ships[\"MMSI\"] == \"636021195\") & (all_ships[\"IMO\"].isnull())].index)\n",
    "all_ships = all_ships.drop(all_ships[(all_ships[\"MMSI\"] == \"240484800\") & (all_ships[\"ShipName\"] == \"nan\")].index)\n",
    "all_ships = all_ships.drop(all_ships[(all_ships[\"MMSI\"] == \"240265600\") & (all_ships[\"ShipName\"] == \"nan\")].index)\n",
    "all_ships = all_ships.drop(all_ships[(all_ships[\"MMSI\"] == \"240159808\") & (all_ships[\"ShipName\"] == \"nan\")].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1de2650",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:20:21.462659Z",
     "start_time": "2024-05-17T12:20:21.433323Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill in ship type nulls with value 99\n",
    "all_ships[\"ShipType\"].fillna(99, inplace=True)\n",
    "\n",
    "# Change ship types to readable values\n",
    "conditions = [\n",
    "    (all_ships[\"ShipType\"].astype(int) == 99),\n",
    "    ((all_ships[\"ShipType\"].astype(int) >= 80) & (all_ships[\"ShipType\"].astype(int) < 90)),\n",
    "    ((all_ships[\"ShipType\"].astype(int) >= 70) & (all_ships[\"ShipType\"].astype(int) < 80)),\n",
    "    ((all_ships[\"ShipType\"].astype(int) >= 60) & (all_ships[\"ShipType\"].astype(int) < 70)),\n",
    "    (all_ships[\"ShipType\"].astype(int) == 52),\n",
    "    ((all_ships[\"ShipType\"].astype(int) >= 30) & (all_ships[\"ShipType\"].astype(int) < 40)),\n",
    "    (all_ships[\"ShipType\"].astype(int) == 0)\n",
    "]\n",
    "\n",
    "values = [\"Unknown\", \"Tanker\", \"Cargo Ship\", \"Passanger Ship\", \"Tug\", \"Generic Vessel\", \"Fishing\"]\n",
    "\n",
    "all_ships['ShipType'] = np.select(conditions, values)\n",
    "\n",
    "# Export all ships for dashboard visalisations\n",
    "all_ships.to_csv(\"./Data/all_ships.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6c28a9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:20:21.490210Z",
     "start_time": "2024-05-17T12:20:21.466844Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop columns not to be used in final project\n",
    "df_ships_data.drop(['CallSign', \"Destination\", \"ETA_Day\", \"ETA_Hour\", \"ETA_Minute\", \"ETA_Month\", \"ShipType\"], axis=1, inplace=True)\n",
    "df_positions.drop(['COG', \"NavigationalStatus\", \"PositionAccuracy\", \"RateOfTurn\", \"SOG\", \"TrueHeading\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e63be571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:20:21.520589Z",
     "start_time": "2024-05-17T12:20:21.503693Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select only oil tankers, cargo ships and unknown type ships\n",
    "potential_tankers = all_ships.loc[all_ships[\"ShipType\"].isin([\"Cargo Ship\", \"Unknown\", \"Tanker\"])]\n",
    "\n",
    "# Select only known oil tankers to csv for dashboard visualisations\n",
    "only_tankers = potential_tankers.loc[potential_tankers[\"ShipType\"] == \"Tanker\"]\n",
    "only_tankers.to_csv(\"./Data/only_tankers.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "209a3e8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:20:21.597098Z",
     "start_time": "2024-05-17T12:20:21.524239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Homogenise MMSIs to string type\n",
    "df_positions = df_positions.astype({\"MMSI\" : str})\n",
    "df_ships_data = df_ships_data.astype({\"MMSI\" : str})\n",
    "\n",
    "# Select only those ships that are tankers, cargo ships or unknown\n",
    "tankers_positions = df_positions[df_positions['MMSI'].isin(potential_tankers[\"MMSI\"].unique())]\n",
    "tankers_ship_data = df_ships_data[df_ships_data['MMSI'].isin(potential_tankers[\"MMSI\"].unique())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "933a1ec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:20:22.837267Z",
     "start_time": "2024-05-17T12:20:21.599389Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge to get all available information about all ships\n",
    "only_flag_mmsi = potential_tankers[[\"MMSI\", \"Flag\", \"ShipType\"]]\n",
    "\n",
    "tankers_positions = pd.merge(tankers_positions, potential_tankers, on=['MMSI', 'ShipName'], how='left')\n",
    "tankers_ship_data = pd.merge(tankers_ship_data, only_flag_mmsi, on=['MMSI'], how='left')\n",
    "\n",
    "# Create a single dataframe with all messages and corresponding ship information\n",
    "all_messages = pd.concat([tankers_positions, tankers_ship_data], axis=0)\n",
    "\n",
    "# Save as CSV file for dashboard visualisations\n",
    "all_messages.to_csv(\"./Data/All_Messages.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b15bb459",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:20:24.219828Z",
     "start_time": "2024-05-17T12:20:22.869557Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert message timestamp to datetime object\n",
    "all_messages[\"start\"] = pd.to_datetime(all_messages[\"UTC_Time\"].str[:-4], format='%Y-%m-%d %H:%M:%S.%f %z')\n",
    "all_messages.drop(\"UTC_Time\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "305b0e73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:20:38.226524Z",
     "start_time": "2024-05-17T12:20:24.239747Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a function to calculate the end of the Popup showing\n",
    "def end_timestamp(df):\n",
    "    output = []\n",
    "    \n",
    "    # Loop through all unique ship license plates\n",
    "    for i in df[\"MMSI\"].unique():\n",
    "        subset = df.loc[df[\"MMSI\"] == i]\n",
    "        \n",
    "        # Prepare the subset dataframe by sorting values by timestamp, creating the end column and reseting the \n",
    "        # index\n",
    "        subset = subset.sort_values(by = \"start\", ascending=True)\n",
    "        subset[\"end\"] = 0\n",
    "        subset.reset_index(inplace=True)\n",
    "        \n",
    "        # Iterate all rows in the subset\n",
    "        for i in range(len(subset)):           \n",
    "        \n",
    "            # If the row is the last instance of the ship seen, delete the popup after 1 day\n",
    "            if i == len(subset) - 1:\n",
    "                subset.loc[i, \"end\"] = subset.loc[i, \"start\"] + pd.Timedelta(days = 1)\n",
    "            # If the row is the not last instance of the ship seen, delete the popup when a new message is available\n",
    "            else:\n",
    "                subset.loc[i, \"end\"] = subset.loc[i + 1, \"start\"]\n",
    "                \n",
    "        output.append(subset)\n",
    "\n",
    "    # Merge the results and return\n",
    "    result = pd.concat(output) \n",
    "    result.drop(\"index\", axis=1, inplace=True) \n",
    "    return result\n",
    "     \n",
    "# Apply function and add to general dataset\n",
    "end_time_df = end_timestamp(all_messages[[\"MMSI\", \"start\"]])\n",
    "all_messages = pd.merge(all_messages, end_time_df, on=['MMSI', 'start'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9c45a78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:20:39.176685Z",
     "start_time": "2024-05-17T12:20:38.229414Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare the GeoJSON file with the fields required\n",
    "all_messages[\"type\"] = \"Point\"\n",
    "all_messages[\"coordinates\"] = [[lat, lon] for lat, lon in zip(all_messages[\"Longitude\"], all_messages[\"Latitude\"])]\n",
    "all_messages.drop([\"Latitude\", \"Longitude\"], axis=1, inplace=True)\n",
    "\n",
    "# Export JSON file for Leaflet map creation\n",
    "all_messages.to_json(\"./Data/All_Messages.json\", orient=\"records\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
